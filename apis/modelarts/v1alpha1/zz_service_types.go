// SPDX-FileCopyrightText: 2024 The Crossplane Authors <https://crossplane.io>
//
// SPDX-License-Identifier: Apache-2.0

// Code generated by upjet. DO NOT EDIT.

package v1alpha1

import (
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime/schema"

	v1 "github.com/crossplane/crossplane-runtime/apis/common/v1"
)

type AdditionalPropertiesInitParameters struct {

	// Advanced Log configuration.
	// The LogReportChannel structure is documented below.
	LogReportChannels []LogReportChannelsInitParameters `json:"logReportChannels,omitempty" tf:"log_report_channels,omitempty"`

	// SMN message notification configuration.
	// The SmnNotification structure is documented below.
	SmnNotification []SmnNotificationInitParameters `json:"smnNotification,omitempty" tf:"smn_notification,omitempty"`
}

type AdditionalPropertiesObservation struct {

	// Advanced Log configuration.
	// The LogReportChannel structure is documented below.
	LogReportChannels []LogReportChannelsObservation `json:"logReportChannels,omitempty" tf:"log_report_channels,omitempty"`

	// SMN message notification configuration.
	// The SmnNotification structure is documented below.
	SmnNotification []SmnNotificationObservation `json:"smnNotification,omitempty" tf:"smn_notification,omitempty"`
}

type AdditionalPropertiesParameters struct {

	// Advanced Log configuration.
	// The LogReportChannel structure is documented below.
	// +kubebuilder:validation:Optional
	LogReportChannels []LogReportChannelsParameters `json:"logReportChannels,omitempty" tf:"log_report_channels,omitempty"`

	// SMN message notification configuration.
	// The SmnNotification structure is documented below.
	// +kubebuilder:validation:Optional
	SmnNotification []SmnNotificationParameters `json:"smnNotification,omitempty" tf:"smn_notification,omitempty"`
}

type ConfigInitParameters struct {

	// parameter must be specified.
	CustomSpec []CustomSpecInitParameters `json:"customSpec,omitempty" tf:"custom_spec,omitempty"`

	// OBS path to the output data of a batch job. Mandatory for batch services.
	// OBS path to the output data of a batch job. Mandatory for batch services.
	DestPath *string `json:"destPath,omitempty" tf:"dest_path,omitempty"`

	// Environment variable key-value pair required for running a model.
	// Environment variable key-value pair required for running a model.
	// +mapType=granular
	Envs map[string]*string `json:"envs,omitempty" tf:"envs,omitempty"`

	// Number of instances deployed for a model.
	// The maximum number of instances is 5. To use more instances, submit a service ticket.
	// Number of instances deployed for a model.
	InstanceCount *float64 `json:"instanceCount,omitempty" tf:"instance_count,omitempty"`

	// Mapping between input parameters and CSV data. Optional for batch services.
	// This parameter is mandatory only when mapping_type is set to csv.
	// The mapping rule is similar to the definition of the input parameters in the config.json file.
	// You only need to configure the index parameters under each parameter of the string, number, integer,
	// or boolean type, and specify the value of this parameter to the values of the index parameters
	// in the CSV file to send an inference request. Use commas (,) to separate multiple pieces of CSV data.
	// The values of the index parameters start from 0. If the value of the index parameter is -1, ignore this parameter.
	// For details, see the sample of creating a batch service.
	// Mapping between input parameters and CSV data. Optional for batch services.
	// +mapType=granular
	MappingRule map[string]*string `json:"mappingRule,omitempty" tf:"mapping_rule,omitempty"`

	// Mapping type of the input data. Mandatory for batch services.
	// The value can be file or csv. file indicates that each inference request corresponds to a file
	// in the input data directory.
	// If this parameter is set to file, req_uri of the model can have only one input parameter and the type
	// of this parameter is file.
	// If this parameter is set to csv, each inference request corresponds to a row of data in the CSV file.
	// When csv is used, the file in the input data directory can only be suffixed with .csv,
	// and the mapping_rule parameter must be configured to map the index of each parameter in
	// the inference request body to the CSV file.
	// Mapping type of the input data. Mandatory for batch services.
	MappingType *string `json:"mappingType,omitempty" tf:"mapping_type,omitempty"`

	// Model ID, which can be obtained by calling the API for obtaining a model list.
	// Model ID, which can be obtained by calling the API for obtaining a model list.
	ModelID *string `json:"modelId,omitempty" tf:"model_id,omitempty"`

	// Edge node ID array. Mandatory for edge services.
	// The node ID is the edge node ID on IEF, which can be obtained after the edge node is created on IEF.
	// Edge node ID array. Mandatory for edge services.
	Nodes []*string `json:"nodes,omitempty" tf:"nodes,omitempty"`

	// The ID of the new dedicated resource pool.
	// When using dedicated resource pool to deploy services, ensure that the cluster status is normal.
	// If both pool_name and config.pool_name are configured, pool_name in real-time config is preferred.
	// ID of a dedicated resource pool. Optional for real-time services.
	PoolName *string `json:"poolName,omitempty" tf:"pool_name,omitempty"`

	// Inference API called in a batch task, which is the RESTful API exposed in the model image.
	// Mandatory for batch services.
	// You must select an API URL from the config.json file of the model for inference.
	// If a built-in inference image of ModelArts is used, the API is displayed as /.
	// Inference API called in a batch task, which is the RESTful API exposed in the model image.
	ReqURI *string `json:"reqUri,omitempty" tf:"req_uri,omitempty"`

	// Resource flavors.
	// The valid values are modelarts.vm.cpu.2u, modelarts.vm.gpu.p4 (must be requested for),
	// modelsarts.vm.ai1.a310 (must be requested for),
	// and custom (available only when the service is deployed in a dedicated resource pool) in the current version.
	// To request for a flavor, submit a service ticket and obtain permissions from ModelArts O&M engineers.
	// If this parameter is set to custom, the custom_spec parameter must be specified.
	// Value options are as follows:
	// Resource flavors.
	Specification *string `json:"specification,omitempty" tf:"specification,omitempty"`

	// OBS path to the input data of a batch job.
	// Mandatory for batch services.
	// OBS path to the input data of a batch job.
	SrcPath *string `json:"srcPath,omitempty" tf:"src_path,omitempty"`

	// Data source type, which can be ManifestFile. Mandatory for batch services.
	// By default, this parameter is left blank, indicating that only files in the src_path directory are read.
	// If this parameter is set to ManifestFile, src_path must be set to a specific manifest path.
	// Multiple data paths can be specified in the manifest file. For details, see the manifest inference specifications.
	// Data source type, which can be ManifestFile. Mandatory for batch services.
	SrcType *string `json:"srcType,omitempty" tf:"src_type,omitempty"`

	// Weight of traffic allocated to a model.
	// This parameter is mandatory only when infer_type is set to real-time.
	// The sum of all weights must be equal to 100. If multiple model versions are configured with different
	// traffic weights in a real-time service, ModelArts will continuously access the prediction API of the
	// service and forward prediction requests to the model instances of the corresponding versions based on the weights.
	// Weight of traffic allocated to a model.
	Weight *float64 `json:"weight,omitempty" tf:"weight,omitempty"`
}

type ConfigObservation struct {

	// parameter must be specified.
	CustomSpec []CustomSpecObservation `json:"customSpec,omitempty" tf:"custom_spec,omitempty"`

	// OBS path to the output data of a batch job. Mandatory for batch services.
	// OBS path to the output data of a batch job. Mandatory for batch services.
	DestPath *string `json:"destPath,omitempty" tf:"dest_path,omitempty"`

	// Environment variable key-value pair required for running a model.
	// Environment variable key-value pair required for running a model.
	// +mapType=granular
	Envs map[string]*string `json:"envs,omitempty" tf:"envs,omitempty"`

	// Number of instances deployed for a model.
	// The maximum number of instances is 5. To use more instances, submit a service ticket.
	// Number of instances deployed for a model.
	InstanceCount *float64 `json:"instanceCount,omitempty" tf:"instance_count,omitempty"`

	// Mapping between input parameters and CSV data. Optional for batch services.
	// This parameter is mandatory only when mapping_type is set to csv.
	// The mapping rule is similar to the definition of the input parameters in the config.json file.
	// You only need to configure the index parameters under each parameter of the string, number, integer,
	// or boolean type, and specify the value of this parameter to the values of the index parameters
	// in the CSV file to send an inference request. Use commas (,) to separate multiple pieces of CSV data.
	// The values of the index parameters start from 0. If the value of the index parameter is -1, ignore this parameter.
	// For details, see the sample of creating a batch service.
	// Mapping between input parameters and CSV data. Optional for batch services.
	// +mapType=granular
	MappingRule map[string]*string `json:"mappingRule,omitempty" tf:"mapping_rule,omitempty"`

	// Mapping type of the input data. Mandatory for batch services.
	// The value can be file or csv. file indicates that each inference request corresponds to a file
	// in the input data directory.
	// If this parameter is set to file, req_uri of the model can have only one input parameter and the type
	// of this parameter is file.
	// If this parameter is set to csv, each inference request corresponds to a row of data in the CSV file.
	// When csv is used, the file in the input data directory can only be suffixed with .csv,
	// and the mapping_rule parameter must be configured to map the index of each parameter in
	// the inference request body to the CSV file.
	// Mapping type of the input data. Mandatory for batch services.
	MappingType *string `json:"mappingType,omitempty" tf:"mapping_type,omitempty"`

	// Model ID, which can be obtained by calling the API for obtaining a model list.
	// Model ID, which can be obtained by calling the API for obtaining a model list.
	ModelID *string `json:"modelId,omitempty" tf:"model_id,omitempty"`

	// Edge node ID array. Mandatory for edge services.
	// The node ID is the edge node ID on IEF, which can be obtained after the edge node is created on IEF.
	// Edge node ID array. Mandatory for edge services.
	Nodes []*string `json:"nodes,omitempty" tf:"nodes,omitempty"`

	// The ID of the new dedicated resource pool.
	// When using dedicated resource pool to deploy services, ensure that the cluster status is normal.
	// If both pool_name and config.pool_name are configured, pool_name in real-time config is preferred.
	// ID of a dedicated resource pool. Optional for real-time services.
	PoolName *string `json:"poolName,omitempty" tf:"pool_name,omitempty"`

	// Inference API called in a batch task, which is the RESTful API exposed in the model image.
	// Mandatory for batch services.
	// You must select an API URL from the config.json file of the model for inference.
	// If a built-in inference image of ModelArts is used, the API is displayed as /.
	// Inference API called in a batch task, which is the RESTful API exposed in the model image.
	ReqURI *string `json:"reqUri,omitempty" tf:"req_uri,omitempty"`

	// Resource flavors.
	// The valid values are modelarts.vm.cpu.2u, modelarts.vm.gpu.p4 (must be requested for),
	// modelsarts.vm.ai1.a310 (must be requested for),
	// and custom (available only when the service is deployed in a dedicated resource pool) in the current version.
	// To request for a flavor, submit a service ticket and obtain permissions from ModelArts O&M engineers.
	// If this parameter is set to custom, the custom_spec parameter must be specified.
	// Value options are as follows:
	// Resource flavors.
	Specification *string `json:"specification,omitempty" tf:"specification,omitempty"`

	// OBS path to the input data of a batch job.
	// Mandatory for batch services.
	// OBS path to the input data of a batch job.
	SrcPath *string `json:"srcPath,omitempty" tf:"src_path,omitempty"`

	// Data source type, which can be ManifestFile. Mandatory for batch services.
	// By default, this parameter is left blank, indicating that only files in the src_path directory are read.
	// If this parameter is set to ManifestFile, src_path must be set to a specific manifest path.
	// Multiple data paths can be specified in the manifest file. For details, see the manifest inference specifications.
	// Data source type, which can be ManifestFile. Mandatory for batch services.
	SrcType *string `json:"srcType,omitempty" tf:"src_type,omitempty"`

	// Weight of traffic allocated to a model.
	// This parameter is mandatory only when infer_type is set to real-time.
	// The sum of all weights must be equal to 100. If multiple model versions are configured with different
	// traffic weights in a real-time service, ModelArts will continuously access the prediction API of the
	// service and forward prediction requests to the model instances of the corresponding versions based on the weights.
	// Weight of traffic allocated to a model.
	Weight *float64 `json:"weight,omitempty" tf:"weight,omitempty"`
}

type ConfigParameters struct {

	// parameter must be specified.
	// +kubebuilder:validation:Optional
	CustomSpec []CustomSpecParameters `json:"customSpec,omitempty" tf:"custom_spec,omitempty"`

	// OBS path to the output data of a batch job. Mandatory for batch services.
	// OBS path to the output data of a batch job. Mandatory for batch services.
	// +kubebuilder:validation:Optional
	DestPath *string `json:"destPath,omitempty" tf:"dest_path,omitempty"`

	// Environment variable key-value pair required for running a model.
	// Environment variable key-value pair required for running a model.
	// +kubebuilder:validation:Optional
	// +mapType=granular
	Envs map[string]*string `json:"envs,omitempty" tf:"envs,omitempty"`

	// Number of instances deployed for a model.
	// The maximum number of instances is 5. To use more instances, submit a service ticket.
	// Number of instances deployed for a model.
	// +kubebuilder:validation:Optional
	InstanceCount *float64 `json:"instanceCount,omitempty" tf:"instance_count,omitempty"`

	// Mapping between input parameters and CSV data. Optional for batch services.
	// This parameter is mandatory only when mapping_type is set to csv.
	// The mapping rule is similar to the definition of the input parameters in the config.json file.
	// You only need to configure the index parameters under each parameter of the string, number, integer,
	// or boolean type, and specify the value of this parameter to the values of the index parameters
	// in the CSV file to send an inference request. Use commas (,) to separate multiple pieces of CSV data.
	// The values of the index parameters start from 0. If the value of the index parameter is -1, ignore this parameter.
	// For details, see the sample of creating a batch service.
	// Mapping between input parameters and CSV data. Optional for batch services.
	// +kubebuilder:validation:Optional
	// +mapType=granular
	MappingRule map[string]*string `json:"mappingRule,omitempty" tf:"mapping_rule,omitempty"`

	// Mapping type of the input data. Mandatory for batch services.
	// The value can be file or csv. file indicates that each inference request corresponds to a file
	// in the input data directory.
	// If this parameter is set to file, req_uri of the model can have only one input parameter and the type
	// of this parameter is file.
	// If this parameter is set to csv, each inference request corresponds to a row of data in the CSV file.
	// When csv is used, the file in the input data directory can only be suffixed with .csv,
	// and the mapping_rule parameter must be configured to map the index of each parameter in
	// the inference request body to the CSV file.
	// Mapping type of the input data. Mandatory for batch services.
	// +kubebuilder:validation:Optional
	MappingType *string `json:"mappingType,omitempty" tf:"mapping_type,omitempty"`

	// Model ID, which can be obtained by calling the API for obtaining a model list.
	// Model ID, which can be obtained by calling the API for obtaining a model list.
	// +kubebuilder:validation:Optional
	ModelID *string `json:"modelId,omitempty" tf:"model_id,omitempty"`

	// Edge node ID array. Mandatory for edge services.
	// The node ID is the edge node ID on IEF, which can be obtained after the edge node is created on IEF.
	// Edge node ID array. Mandatory for edge services.
	// +kubebuilder:validation:Optional
	Nodes []*string `json:"nodes,omitempty" tf:"nodes,omitempty"`

	// The ID of the new dedicated resource pool.
	// When using dedicated resource pool to deploy services, ensure that the cluster status is normal.
	// If both pool_name and config.pool_name are configured, pool_name in real-time config is preferred.
	// ID of a dedicated resource pool. Optional for real-time services.
	// +kubebuilder:validation:Optional
	PoolName *string `json:"poolName,omitempty" tf:"pool_name,omitempty"`

	// Inference API called in a batch task, which is the RESTful API exposed in the model image.
	// Mandatory for batch services.
	// You must select an API URL from the config.json file of the model for inference.
	// If a built-in inference image of ModelArts is used, the API is displayed as /.
	// Inference API called in a batch task, which is the RESTful API exposed in the model image.
	// +kubebuilder:validation:Optional
	ReqURI *string `json:"reqUri,omitempty" tf:"req_uri,omitempty"`

	// Resource flavors.
	// The valid values are modelarts.vm.cpu.2u, modelarts.vm.gpu.p4 (must be requested for),
	// modelsarts.vm.ai1.a310 (must be requested for),
	// and custom (available only when the service is deployed in a dedicated resource pool) in the current version.
	// To request for a flavor, submit a service ticket and obtain permissions from ModelArts O&M engineers.
	// If this parameter is set to custom, the custom_spec parameter must be specified.
	// Value options are as follows:
	// Resource flavors.
	// +kubebuilder:validation:Optional
	Specification *string `json:"specification,omitempty" tf:"specification,omitempty"`

	// OBS path to the input data of a batch job.
	// Mandatory for batch services.
	// OBS path to the input data of a batch job.
	// +kubebuilder:validation:Optional
	SrcPath *string `json:"srcPath,omitempty" tf:"src_path,omitempty"`

	// Data source type, which can be ManifestFile. Mandatory for batch services.
	// By default, this parameter is left blank, indicating that only files in the src_path directory are read.
	// If this parameter is set to ManifestFile, src_path must be set to a specific manifest path.
	// Multiple data paths can be specified in the manifest file. For details, see the manifest inference specifications.
	// Data source type, which can be ManifestFile. Mandatory for batch services.
	// +kubebuilder:validation:Optional
	SrcType *string `json:"srcType,omitempty" tf:"src_type,omitempty"`

	// Weight of traffic allocated to a model.
	// This parameter is mandatory only when infer_type is set to real-time.
	// The sum of all weights must be equal to 100. If multiple model versions are configured with different
	// traffic weights in a real-time service, ModelArts will continuously access the prediction API of the
	// service and forward prediction requests to the model instances of the corresponding versions based on the weights.
	// Weight of traffic allocated to a model.
	// +kubebuilder:validation:Optional
	Weight *float64 `json:"weight,omitempty" tf:"weight,omitempty"`
}

type CustomSpecInitParameters struct {

	// Number of Ascend chips. Either this parameter or gpu_p4 is configured.
	// Number of Ascend chips. Either this parameter or **gpu_p4** is configured.
	AscendA310 *float64 `json:"ascendA310,omitempty" tf:"ascend_a310,omitempty"`

	// Number of CPU cores, which can be a decimal. The value cannot be smaller than 0.01.
	// Number of CPU cores, which can be a decimal. The value cannot be smaller than 0.01.
	CPU *float64 `json:"cpu,omitempty" tf:"cpu,omitempty"`

	// Number of GPU cores, which can be a decimal.
	// The value cannot be smaller than 0, which allows up to two decimal places.
	// Number of GPU cores, which can be a decimal.
	GpuP4 *float64 `json:"gpuP4,omitempty" tf:"gpu_p4,omitempty"`

	// Memory in MB, which must be an integer.
	// Memory in MB, which must be an integer.
	Memory *float64 `json:"memory,omitempty" tf:"memory,omitempty"`
}

type CustomSpecObservation struct {

	// Number of Ascend chips. Either this parameter or gpu_p4 is configured.
	// Number of Ascend chips. Either this parameter or **gpu_p4** is configured.
	AscendA310 *float64 `json:"ascendA310,omitempty" tf:"ascend_a310,omitempty"`

	// Number of CPU cores, which can be a decimal. The value cannot be smaller than 0.01.
	// Number of CPU cores, which can be a decimal. The value cannot be smaller than 0.01.
	CPU *float64 `json:"cpu,omitempty" tf:"cpu,omitempty"`

	// Number of GPU cores, which can be a decimal.
	// The value cannot be smaller than 0, which allows up to two decimal places.
	// Number of GPU cores, which can be a decimal.
	GpuP4 *float64 `json:"gpuP4,omitempty" tf:"gpu_p4,omitempty"`

	// Memory in MB, which must be an integer.
	// Memory in MB, which must be an integer.
	Memory *float64 `json:"memory,omitempty" tf:"memory,omitempty"`
}

type CustomSpecParameters struct {

	// Number of Ascend chips. Either this parameter or gpu_p4 is configured.
	// Number of Ascend chips. Either this parameter or **gpu_p4** is configured.
	// +kubebuilder:validation:Optional
	AscendA310 *float64 `json:"ascendA310,omitempty" tf:"ascend_a310,omitempty"`

	// Number of CPU cores, which can be a decimal. The value cannot be smaller than 0.01.
	// Number of CPU cores, which can be a decimal. The value cannot be smaller than 0.01.
	// +kubebuilder:validation:Optional
	CPU *float64 `json:"cpu,omitempty" tf:"cpu,omitempty"`

	// Number of GPU cores, which can be a decimal.
	// The value cannot be smaller than 0, which allows up to two decimal places.
	// Number of GPU cores, which can be a decimal.
	// +kubebuilder:validation:Optional
	GpuP4 *float64 `json:"gpuP4,omitempty" tf:"gpu_p4,omitempty"`

	// Memory in MB, which must be an integer.
	// Memory in MB, which must be an integer.
	// +kubebuilder:validation:Optional
	Memory *float64 `json:"memory,omitempty" tf:"memory,omitempty"`
}

type LogReportChannelsInitParameters struct {

	// Scheduling type. Only the value stop is supported.
	// The type of log report channel. The valid value is **LTS**.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type LogReportChannelsObservation struct {

	// Scheduling type. Only the value stop is supported.
	// The type of log report channel. The valid value is **LTS**.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type LogReportChannelsParameters struct {

	// Scheduling type. Only the value stop is supported.
	// The type of log report channel. The valid value is **LTS**.
	// +kubebuilder:validation:Optional
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type ScheduleInitParameters struct {

	// Value mapping a time unit.
	// For example, if the task stops after two hours, set time_unit to HOURS and duration to 2.
	// Value mapping a time unit.
	Duration *float64 `json:"duration,omitempty" tf:"duration,omitempty"`

	// Scheduling time unit. Possible values are DAYS, HOURS, and MINUTES.
	// Scheduling time unit. Possible values are DAYS, HOURS, and MINUTES.
	TimeUnit *string `json:"timeUnit,omitempty" tf:"time_unit,omitempty"`

	// Scheduling type. Only the value stop is supported.
	// Scheduling type. Only the value **stop** is supported.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type ScheduleObservation struct {

	// Value mapping a time unit.
	// For example, if the task stops after two hours, set time_unit to HOURS and duration to 2.
	// Value mapping a time unit.
	Duration *float64 `json:"duration,omitempty" tf:"duration,omitempty"`

	// Scheduling time unit. Possible values are DAYS, HOURS, and MINUTES.
	// Scheduling time unit. Possible values are DAYS, HOURS, and MINUTES.
	TimeUnit *string `json:"timeUnit,omitempty" tf:"time_unit,omitempty"`

	// Scheduling type. Only the value stop is supported.
	// Scheduling type. Only the value **stop** is supported.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type ScheduleParameters struct {

	// Value mapping a time unit.
	// For example, if the task stops after two hours, set time_unit to HOURS and duration to 2.
	// Value mapping a time unit.
	// +kubebuilder:validation:Optional
	Duration *float64 `json:"duration" tf:"duration,omitempty"`

	// Scheduling time unit. Possible values are DAYS, HOURS, and MINUTES.
	// Scheduling time unit. Possible values are DAYS, HOURS, and MINUTES.
	// +kubebuilder:validation:Optional
	TimeUnit *string `json:"timeUnit" tf:"time_unit,omitempty"`

	// Scheduling type. Only the value stop is supported.
	// Scheduling type. Only the value **stop** is supported.
	// +kubebuilder:validation:Optional
	Type *string `json:"type" tf:"type,omitempty"`
}

type ServiceInitParameters struct {

	// Additional properties.
	// The AdditionalProperty structure is documented below.
	AdditionalProperties []AdditionalPropertiesInitParameters `json:"additionalProperties,omitempty" tf:"additional_properties,omitempty"`

	// Which status you want to change the service to.
	// The valid value can be running or stopped.
	// If this parameter is not configured, the service status is not changed.
	// Which status you want to change the service to, the valid value can be **running** or **stopped**.
	ChangeStatusTo *string `json:"changeStatusTo,omitempty" tf:"change_status_to,omitempty"`

	// Model running configurations.
	// If infer_type is batch or edge, you can configure only one model.
	// If infer_type is real-time, you can configure multiple models and assign weights based on service requirements.
	// However, the versions of multiple models must be unique.
	// The Config structure is documented below.
	Config []ConfigInitParameters `json:"config,omitempty" tf:"config,omitempty"`

	// The description of the service.
	// The description of the service.
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// Inference mode.
	// Value options are as follows:
	// Inference mode.
	InferType *string `json:"inferType,omitempty" tf:"infer_type,omitempty"`

	// Service name, which consists of 1 to 64 characters.
	// Only letters, digits, hyphens (-), and underscores (_) are allowed.
	// Service name, which consists of 1 to 64 characters.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// The ID of the new dedicated resource pool.
	// When using dedicated resource pool to deploy services, ensure that the cluster status is normal.
	// If both pool_name and config.pool_name are configured, pool_name in real-time config is preferred.
	// Specifies the ID of the new dedicated resource pool.
	PoolName *string `json:"poolName,omitempty" tf:"pool_name,omitempty"`

	// Specifies the region in which to create the resource.
	// If omitted, the provider-level region will be used. Changing this parameter will create a new resource.
	Region *string `json:"region,omitempty" tf:"region,omitempty"`

	// Service scheduling configuration, which can be configured only for real-time services.
	// If this parameter is configured, the service will be stopped automatically.
	// By default, the service runs for a long time.
	// The Schedule structure is documented below.
	Schedule []ScheduleInitParameters `json:"schedule,omitempty" tf:"schedule,omitempty"`

	// The security group ID.
	// By default, this parameter is left blank.
	// This parameter is mandatory if vpc_id is configured.
	// A security group is a virtual firewall that provides secure network access control policies for service instances.
	// A security group must contain at least one inbound rule to permit the requests whose protocol is TCP,
	// source address is 0.0.0.0/0, and port number is 8080.
	// The security group ID.
	// +crossplane:generate:reference:type=github.com/huaweicloud/provider-huaweicloud/apis/vpc/v1alpha1.Secgroup
	// +crossplane:generate:reference:extractor=github.com/crossplane/upjet/pkg/resource.ExtractResourceID()
	SecurityGroupID *string `json:"securityGroupId,omitempty" tf:"security_group_id,omitempty"`

	// Reference to a Secgroup in vpc to populate securityGroupId.
	// +kubebuilder:validation:Optional
	SecurityGroupIDRef *v1.Reference `json:"securityGroupIdRef,omitempty" tf:"-"`

	// Selector for a Secgroup in vpc to populate securityGroupId.
	// +kubebuilder:validation:Optional
	SecurityGroupIDSelector *v1.Selector `json:"securityGroupIdSelector,omitempty" tf:"-"`

	// The subnet ID.
	// By default, this parameter is left blank.
	// This parameter is mandatory if vpc_id is configured.
	// Enter the network ID displayed in the subnet details on the VPC management console.
	// A subnet provides dedicated network resources that are isolated from other networks.
	// The subnet ID.
	// +crossplane:generate:reference:type=github.com/huaweicloud/provider-huaweicloud/apis/vpc/v1alpha1.Subnet
	// +crossplane:generate:reference:extractor=github.com/crossplane/upjet/pkg/resource.ExtractResourceID()
	SubnetID *string `json:"subnetId,omitempty" tf:"subnet_id,omitempty"`

	// Reference to a Subnet in vpc to populate subnetId.
	// +kubebuilder:validation:Optional
	SubnetIDRef *v1.Reference `json:"subnetIdRef,omitempty" tf:"-"`

	// Selector for a Subnet in vpc to populate subnetId.
	// +kubebuilder:validation:Optional
	SubnetIDSelector *v1.Selector `json:"subnetIdSelector,omitempty" tf:"-"`

	// The VPC ID to which a real-time service instance is deployed.
	// By default, this parameter is left blank. In this case, ModelArts allocates a dedicated VPC to each user,
	// and users are isolated from each other.
	// To access other service components in the VPC of the service instance,
	// set this parameter to the ID of the corresponding VPC.
	// Once a VPC is configured, it cannot be modified. If both vpc_id and pool_name are configured,
	// only the dedicated resource pool takes effect.
	// The VPC ID to which a real-time service instance is deployed.
	// +crossplane:generate:reference:type=github.com/huaweicloud/provider-huaweicloud/apis/vpc/v1alpha1.VPC
	// +crossplane:generate:reference:extractor=github.com/crossplane/upjet/pkg/resource.ExtractResourceID()
	VPCID *string `json:"vpcId,omitempty" tf:"vpc_id,omitempty"`

	// Reference to a VPC in vpc to populate vpcId.
	// +kubebuilder:validation:Optional
	VPCIDRef *v1.Reference `json:"vpcIdRef,omitempty" tf:"-"`

	// Selector for a VPC in vpc to populate vpcId.
	// +kubebuilder:validation:Optional
	VPCIDSelector *v1.Selector `json:"vpcIdSelector,omitempty" tf:"-"`

	// ID of the workspace to which a service belongs.
	// The default value is 0, indicating the default workspace.
	// ID of the workspace to which a service belongs.
	// +crossplane:generate:reference:type=github.com/huaweicloud/provider-huaweicloud/apis/modelarts/v1alpha1.Workspace
	// +crossplane:generate:reference:extractor=github.com/crossplane/upjet/pkg/resource.ExtractResourceID()
	WorkspaceID *string `json:"workspaceId,omitempty" tf:"workspace_id,omitempty"`

	// Reference to a Workspace in modelarts to populate workspaceId.
	// +kubebuilder:validation:Optional
	WorkspaceIDRef *v1.Reference `json:"workspaceIdRef,omitempty" tf:"-"`

	// Selector for a Workspace in modelarts to populate workspaceId.
	// +kubebuilder:validation:Optional
	WorkspaceIDSelector *v1.Selector `json:"workspaceIdSelector,omitempty" tf:"-"`
}

type ServiceObservation struct {

	// Access address of an inference request.
	// This parameter is available when infer_type is set to real-time.
	// Access address of an inference request.
	AccessAddress *string `json:"accessAddress,omitempty" tf:"access_address,omitempty"`

	// Additional properties.
	// The AdditionalProperty structure is documented below.
	AdditionalProperties []AdditionalPropertiesObservation `json:"additionalProperties,omitempty" tf:"additional_properties,omitempty"`

	// Request address of a custom domain name.
	// This parameter is available after a domain name is bound.
	// Request address of a custom domain name.
	BindAccessAddress *string `json:"bindAccessAddress,omitempty" tf:"bind_access_address,omitempty"`

	// Which status you want to change the service to.
	// The valid value can be running or stopped.
	// If this parameter is not configured, the service status is not changed.
	// Which status you want to change the service to, the valid value can be **running** or **stopped**.
	ChangeStatusTo *string `json:"changeStatusTo,omitempty" tf:"change_status_to,omitempty"`

	// Model running configurations.
	// If infer_type is batch or edge, you can configure only one model.
	// If infer_type is real-time, you can configure multiple models and assign weights based on service requirements.
	// However, the versions of multiple models must be unique.
	// The Config structure is documented below.
	Config []ConfigObservation `json:"config,omitempty" tf:"config,omitempty"`

	// Online debugging address of a real-time service.
	// This parameter is available only when the model supports online debugging and there is only one instance.
	// Online debugging address of a real-time service.
	DebugURL *string `json:"debugUrl,omitempty" tf:"debug_url,omitempty"`

	// The description of the service.
	// The description of the service.
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// Number of failed service calls.
	// Number of failed service calls.
	FailedTimes *float64 `json:"failedTimes,omitempty" tf:"failed_times,omitempty"`

	// The resource ID.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`

	// Inference mode.
	// Value options are as follows:
	// Inference mode.
	InferType *string `json:"inferType,omitempty" tf:"infer_type,omitempty"`

	// Total number of service calls.
	// Total number of service calls.
	InvocationTimes *float64 `json:"invocationTimes,omitempty" tf:"invocation_times,omitempty"`

	// Whether a free-of-charge flavor is used.
	// Whether a free-of-charge flavor is used.
	IsFree *bool `json:"isFree,omitempty" tf:"is_free,omitempty"`

	// Whether a service is subscribed.
	// Whether a service is subscribed.
	IsShared *bool `json:"isShared,omitempty" tf:"is_shared,omitempty"`

	// Service name, which consists of 1 to 64 characters.
	// Only letters, digits, hyphens (-), and underscores (_) are allowed.
	// Service name, which consists of 1 to 64 characters.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// User to which a service belongs
	// User to which a service belongs
	Owner *string `json:"owner,omitempty" tf:"owner,omitempty"`

	// The ID of the new dedicated resource pool.
	// When using dedicated resource pool to deploy services, ensure that the cluster status is normal.
	// If both pool_name and config.pool_name are configured, pool_name in real-time config is preferred.
	// Specifies the ID of the new dedicated resource pool.
	PoolName *string `json:"poolName,omitempty" tf:"pool_name,omitempty"`

	// Specifies the region in which to create the resource.
	// If omitted, the provider-level region will be used. Changing this parameter will create a new resource.
	Region *string `json:"region,omitempty" tf:"region,omitempty"`

	// Service scheduling configuration, which can be configured only for real-time services.
	// If this parameter is configured, the service will be stopped automatically.
	// By default, the service runs for a long time.
	// The Schedule structure is documented below.
	Schedule []ScheduleObservation `json:"schedule,omitempty" tf:"schedule,omitempty"`

	// The security group ID.
	// By default, this parameter is left blank.
	// This parameter is mandatory if vpc_id is configured.
	// A security group is a virtual firewall that provides secure network access control policies for service instances.
	// A security group must contain at least one inbound rule to permit the requests whose protocol is TCP,
	// source address is 0.0.0.0/0, and port number is 8080.
	// The security group ID.
	SecurityGroupID *string `json:"securityGroupId,omitempty" tf:"security_group_id,omitempty"`

	// Number of subscribed services.
	// Number of subscribed services.
	SharedCount *float64 `json:"sharedCount,omitempty" tf:"shared_count,omitempty"`

	// Service status.
	// Value options are as follows:
	// Service status.
	Status *string `json:"status,omitempty" tf:"status,omitempty"`

	// The subnet ID.
	// By default, this parameter is left blank.
	// This parameter is mandatory if vpc_id is configured.
	// Enter the network ID displayed in the subnet details on the VPC management console.
	// A subnet provides dedicated network resources that are isolated from other networks.
	// The subnet ID.
	SubnetID *string `json:"subnetId,omitempty" tf:"subnet_id,omitempty"`

	// The VPC ID to which a real-time service instance is deployed.
	// By default, this parameter is left blank. In this case, ModelArts allocates a dedicated VPC to each user,
	// and users are isolated from each other.
	// To access other service components in the VPC of the service instance,
	// set this parameter to the ID of the corresponding VPC.
	// Once a VPC is configured, it cannot be modified. If both vpc_id and pool_name are configured,
	// only the dedicated resource pool takes effect.
	// The VPC ID to which a real-time service instance is deployed.
	VPCID *string `json:"vpcId,omitempty" tf:"vpc_id,omitempty"`

	// ID of the workspace to which a service belongs.
	// The default value is 0, indicating the default workspace.
	// ID of the workspace to which a service belongs.
	WorkspaceID *string `json:"workspaceId,omitempty" tf:"workspace_id,omitempty"`
}

type ServiceParameters struct {

	// Additional properties.
	// The AdditionalProperty structure is documented below.
	// +kubebuilder:validation:Optional
	AdditionalProperties []AdditionalPropertiesParameters `json:"additionalProperties,omitempty" tf:"additional_properties,omitempty"`

	// Which status you want to change the service to.
	// The valid value can be running or stopped.
	// If this parameter is not configured, the service status is not changed.
	// Which status you want to change the service to, the valid value can be **running** or **stopped**.
	// +kubebuilder:validation:Optional
	ChangeStatusTo *string `json:"changeStatusTo,omitempty" tf:"change_status_to,omitempty"`

	// Model running configurations.
	// If infer_type is batch or edge, you can configure only one model.
	// If infer_type is real-time, you can configure multiple models and assign weights based on service requirements.
	// However, the versions of multiple models must be unique.
	// The Config structure is documented below.
	// +kubebuilder:validation:Optional
	Config []ConfigParameters `json:"config,omitempty" tf:"config,omitempty"`

	// The description of the service.
	// The description of the service.
	// +kubebuilder:validation:Optional
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// Inference mode.
	// Value options are as follows:
	// Inference mode.
	// +kubebuilder:validation:Optional
	InferType *string `json:"inferType,omitempty" tf:"infer_type,omitempty"`

	// Service name, which consists of 1 to 64 characters.
	// Only letters, digits, hyphens (-), and underscores (_) are allowed.
	// Service name, which consists of 1 to 64 characters.
	// +kubebuilder:validation:Optional
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// The ID of the new dedicated resource pool.
	// When using dedicated resource pool to deploy services, ensure that the cluster status is normal.
	// If both pool_name and config.pool_name are configured, pool_name in real-time config is preferred.
	// Specifies the ID of the new dedicated resource pool.
	// +kubebuilder:validation:Optional
	PoolName *string `json:"poolName,omitempty" tf:"pool_name,omitempty"`

	// Specifies the region in which to create the resource.
	// If omitted, the provider-level region will be used. Changing this parameter will create a new resource.
	// +kubebuilder:validation:Optional
	Region *string `json:"region,omitempty" tf:"region,omitempty"`

	// Service scheduling configuration, which can be configured only for real-time services.
	// If this parameter is configured, the service will be stopped automatically.
	// By default, the service runs for a long time.
	// The Schedule structure is documented below.
	// +kubebuilder:validation:Optional
	Schedule []ScheduleParameters `json:"schedule,omitempty" tf:"schedule,omitempty"`

	// The security group ID.
	// By default, this parameter is left blank.
	// This parameter is mandatory if vpc_id is configured.
	// A security group is a virtual firewall that provides secure network access control policies for service instances.
	// A security group must contain at least one inbound rule to permit the requests whose protocol is TCP,
	// source address is 0.0.0.0/0, and port number is 8080.
	// The security group ID.
	// +crossplane:generate:reference:type=github.com/huaweicloud/provider-huaweicloud/apis/vpc/v1alpha1.Secgroup
	// +crossplane:generate:reference:extractor=github.com/crossplane/upjet/pkg/resource.ExtractResourceID()
	// +kubebuilder:validation:Optional
	SecurityGroupID *string `json:"securityGroupId,omitempty" tf:"security_group_id,omitempty"`

	// Reference to a Secgroup in vpc to populate securityGroupId.
	// +kubebuilder:validation:Optional
	SecurityGroupIDRef *v1.Reference `json:"securityGroupIdRef,omitempty" tf:"-"`

	// Selector for a Secgroup in vpc to populate securityGroupId.
	// +kubebuilder:validation:Optional
	SecurityGroupIDSelector *v1.Selector `json:"securityGroupIdSelector,omitempty" tf:"-"`

	// The subnet ID.
	// By default, this parameter is left blank.
	// This parameter is mandatory if vpc_id is configured.
	// Enter the network ID displayed in the subnet details on the VPC management console.
	// A subnet provides dedicated network resources that are isolated from other networks.
	// The subnet ID.
	// +crossplane:generate:reference:type=github.com/huaweicloud/provider-huaweicloud/apis/vpc/v1alpha1.Subnet
	// +crossplane:generate:reference:extractor=github.com/crossplane/upjet/pkg/resource.ExtractResourceID()
	// +kubebuilder:validation:Optional
	SubnetID *string `json:"subnetId,omitempty" tf:"subnet_id,omitempty"`

	// Reference to a Subnet in vpc to populate subnetId.
	// +kubebuilder:validation:Optional
	SubnetIDRef *v1.Reference `json:"subnetIdRef,omitempty" tf:"-"`

	// Selector for a Subnet in vpc to populate subnetId.
	// +kubebuilder:validation:Optional
	SubnetIDSelector *v1.Selector `json:"subnetIdSelector,omitempty" tf:"-"`

	// The VPC ID to which a real-time service instance is deployed.
	// By default, this parameter is left blank. In this case, ModelArts allocates a dedicated VPC to each user,
	// and users are isolated from each other.
	// To access other service components in the VPC of the service instance,
	// set this parameter to the ID of the corresponding VPC.
	// Once a VPC is configured, it cannot be modified. If both vpc_id and pool_name are configured,
	// only the dedicated resource pool takes effect.
	// The VPC ID to which a real-time service instance is deployed.
	// +crossplane:generate:reference:type=github.com/huaweicloud/provider-huaweicloud/apis/vpc/v1alpha1.VPC
	// +crossplane:generate:reference:extractor=github.com/crossplane/upjet/pkg/resource.ExtractResourceID()
	// +kubebuilder:validation:Optional
	VPCID *string `json:"vpcId,omitempty" tf:"vpc_id,omitempty"`

	// Reference to a VPC in vpc to populate vpcId.
	// +kubebuilder:validation:Optional
	VPCIDRef *v1.Reference `json:"vpcIdRef,omitempty" tf:"-"`

	// Selector for a VPC in vpc to populate vpcId.
	// +kubebuilder:validation:Optional
	VPCIDSelector *v1.Selector `json:"vpcIdSelector,omitempty" tf:"-"`

	// ID of the workspace to which a service belongs.
	// The default value is 0, indicating the default workspace.
	// ID of the workspace to which a service belongs.
	// +crossplane:generate:reference:type=github.com/huaweicloud/provider-huaweicloud/apis/modelarts/v1alpha1.Workspace
	// +crossplane:generate:reference:extractor=github.com/crossplane/upjet/pkg/resource.ExtractResourceID()
	// +kubebuilder:validation:Optional
	WorkspaceID *string `json:"workspaceId,omitempty" tf:"workspace_id,omitempty"`

	// Reference to a Workspace in modelarts to populate workspaceId.
	// +kubebuilder:validation:Optional
	WorkspaceIDRef *v1.Reference `json:"workspaceIdRef,omitempty" tf:"-"`

	// Selector for a Workspace in modelarts to populate workspaceId.
	// +kubebuilder:validation:Optional
	WorkspaceIDSelector *v1.Selector `json:"workspaceIdSelector,omitempty" tf:"-"`
}

type SmnNotificationInitParameters struct {

	// Event ID.
	// Value options are as follows:
	// Event ID.
	Events []*float64 `json:"events,omitempty" tf:"events,omitempty"`

	// URN of an SMN topic.
	// URN of an SMN topic.
	TopicUrn *string `json:"topicUrn,omitempty" tf:"topic_urn,omitempty"`
}

type SmnNotificationObservation struct {

	// Event ID.
	// Value options are as follows:
	// Event ID.
	Events []*float64 `json:"events,omitempty" tf:"events,omitempty"`

	// URN of an SMN topic.
	// URN of an SMN topic.
	TopicUrn *string `json:"topicUrn,omitempty" tf:"topic_urn,omitempty"`
}

type SmnNotificationParameters struct {

	// Event ID.
	// Value options are as follows:
	// Event ID.
	// +kubebuilder:validation:Optional
	Events []*float64 `json:"events,omitempty" tf:"events,omitempty"`

	// URN of an SMN topic.
	// URN of an SMN topic.
	// +kubebuilder:validation:Optional
	TopicUrn *string `json:"topicUrn,omitempty" tf:"topic_urn,omitempty"`
}

// ServiceSpec defines the desired state of Service
type ServiceSpec struct {
	v1.ResourceSpec `json:",inline"`
	ForProvider     ServiceParameters `json:"forProvider"`
	// THIS IS A BETA FIELD. It will be honored
	// unless the Management Policies feature flag is disabled.
	// InitProvider holds the same fields as ForProvider, with the exception
	// of Identifier and other resource reference fields. The fields that are
	// in InitProvider are merged into ForProvider when the resource is created.
	// The same fields are also added to the terraform ignore_changes hook, to
	// avoid updating them after creation. This is useful for fields that are
	// required on creation, but we do not desire to update them after creation,
	// for example because of an external controller is managing them, like an
	// autoscaler.
	InitProvider ServiceInitParameters `json:"initProvider,omitempty"`
}

// ServiceStatus defines the observed state of Service.
type ServiceStatus struct {
	v1.ResourceStatus `json:",inline"`
	AtProvider        ServiceObservation `json:"atProvider,omitempty"`
}

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status
// +kubebuilder:storageversion

// Service is the Schema for the Services API. ""
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:resource:scope=Cluster,categories={crossplane,managed,huaweicloud}
type Service struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.config) || (has(self.initProvider) && has(self.initProvider.config))",message="spec.forProvider.config is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.inferType) || (has(self.initProvider) && has(self.initProvider.inferType))",message="spec.forProvider.inferType is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.name) || (has(self.initProvider) && has(self.initProvider.name))",message="spec.forProvider.name is a required parameter"
	Spec   ServiceSpec   `json:"spec"`
	Status ServiceStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// ServiceList contains a list of Services
type ServiceList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []Service `json:"items"`
}

// Repository type metadata.
var (
	Service_Kind             = "Service"
	Service_GroupKind        = schema.GroupKind{Group: CRDGroup, Kind: Service_Kind}.String()
	Service_KindAPIVersion   = Service_Kind + "." + CRDGroupVersion.String()
	Service_GroupVersionKind = CRDGroupVersion.WithKind(Service_Kind)
)

func init() {
	SchemeBuilder.Register(&Service{}, &ServiceList{})
}
